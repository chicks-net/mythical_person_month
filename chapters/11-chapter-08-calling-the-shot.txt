8
Calling the Shot

8
Calling the Shot
Practice is the best of all instructors.
PUBUUUS
Experience is a dear teacher, but fools will learn at no
other.
POOR RICHARD'S ALMANAC
Douglass Crockwell, "Ruth calls his shot," World Series, 1932
Reproduced by permission of Esquire Magazine and Douglass Crockwell, © 1945
(renewed 1973) by Esquire, Inc., and courtesy of the National Baseball Museum.
87
88 Calling the Shot
How long will a system programming job take? How much effort
will be required? How does one estimate?
I have earlier suggested ratios that seem to apply to planning
time, coding, component test, and system test. First, one must say
that one does not estimate the entire task by estimating the coding
portion only and then applying the ratios. The coding is only
one-sixth or so of the problem, and errors in its estimate or in the
ratios could lead to ridiculous'results.
Second, one must say that data for building isolated small
programs are not applicable to programming systems products. For
a program averaging about 3200 words, for example, Sackman,
Erikson, and Grant report an average code-plus-debug time of
about 178 hours for a single programmer, a figure which would
extrapolate to give an annual productivity of 35,800 statements
per year. A program half that size took less than one-fourth as
long, and extrapolated productivity is almost 80,000 statements
per year.1 Planning, documentation, testing, system integration,
and training times must be added. The linear extrapolation of such
sprint figures is meaningless. Extrapolation of times for the hun-
dred-yard dash shows that a man can run a mile in under three
minutes.
Before dismissing them, however, let us note that these num-
bers, although not for strictly comparable problems, suggest that
effort goes as a power of size even when no communication is
involved except that of a man with his memories.
Figure 8.1 tells the sad story. It illustrates results reported from
a study done by Nanus and Farr2 at System Development Corpo-
ration. This shows an exponent of 1.5; that is,
effort = (constant) X (number of instructions)15.
Another SDC study reported by Weinwurm3 also shows an expo-
nent near 1.5.
A few studies on programmer productivity have been made,
and several estimating techniques have been proposed. Morin has
prepared a survey of the published data.4 Here I shall give only a
few items that seem especially illuminating.
Portman's Data 89
Fig. 8.1 Programming effort as a function of program size
Portman's Data
Charles Portman, manager of ICL's Software Division, Computer
Equipment Organization (Northwest) at Manchester, offers an-
other useful personal insight.5
He found his programming teams missing schedules by about
one-half—each job was taking approximately twice as long as
estimated. The estimates were very careful, done by experienced
teams estimating man-hours for several hundred subtasks on a
PERT chart. When the slippage pattern appeared, he asked them
to keep careful daily logs of time usage. These showed that the
estimating error could be entirely accounted for by the fact that
his teams were only realizing 50 percent of the working week as
actual programming and debugging time. Machine downtime,
higher-priority short unrelated jobs, meetings, paperwork, com-
Thousands of machine instructions
90 Calling the Shot
pany business, sickness, personal time, etc. accounted for the rest.
In short, the estimates made an unrealistic assumption about the
number of technical work hours per man-year. My own experi-
ence quite confirms his conclusion.6
Aron's Data
Joel Aron, manager of Systems Technology at IBM in Gaithers-
burg, Maryland, has studied programmer productivity when
working on nine large systems (briefly, large means more than 25
programmers and 30,000 deliverable instructions).7 He divides
such systems according to interactions among programmers (and
system parts) and finds productivities as follows:
Very few interactions 10,000 instructions per man-year
Some interactions 5,000
Many interactions 1,500
The man-years do not include support and system test activi-
ties, only design and programming. When these figures are diluted
by a factor of two to cover system test, they closely match Harr's
data.
Harr's Data
John Hair, manager of programming for the Bell Telephone Labo-
ratories' Electronic Switching System, reported his and others'
experience in a paper at the 1969 Spring Joint Computer Confer-
ence.8 These data are shown in Figs. 8.2, 8.3, and 8.4.
Of these, Fig. 8.2 is the most detailed and the most useful. The
first two jobs are basically control programs; the second two are
basically language translators. Productivity is stated in terms of
debugged words per man-year. This includes programming, com-
ponent test, and system test. It is not clear how much of the
planning effort, or effort in machine support, writing, and the like,
is included.
Han's Data 91
Operational
Maintenance
Compiler
Translator
(Data assembler)
units
50
36
13
15
Number of
programmers
S3
60
9
13
Years
4
4
•2'A
2%
Maa-
years
101
81
1?
11
Program
words
52,OQG
51,000
38,000
25,000
Words/'
man-yf
515
630
2270
Fig. 8.2 Summary of four No. 1 ESS program jobs
The productivities likewise fall into two classifications; those
for control programs are about 600 words per man-year; those for
translators are about 2200 words per man-year. Note that all four
programs are of similar size—the variation is in size of the work
groups, length of time, and number of modules. Which is cause
and which is effect? Did the control programs require more people
because they were more complicated? Or did they require more
modules and more man-months because they were assigned more
people? Did they take longer because of the greater complexity,
or because more people were assigned? One can't be sure. The
control programs were surely more complex. These uncertainties
aside, the numbers describe the real productivities achieved on a
large system, using present-day programming techniques. As such
they are a real contribution.
Figures 8.3 and 8.4 show some interesting data on program-
ming and debugging rates as-compared to predicted rates.
Fig. 8.3 ESS predicted and actual programming rates
Fig. 8.4 ESS predicted and actual debugging rates
92 Calling the Shot
Corbatd's Data 93
OS/360 Data
IBM OS/360 experience, while not available in the detail of Hair's
data, confirms it. Productivities in range of 600-800 debugged
instructions per man-year were experienced by control program
groups. Productivities in the 2000-3000 debugged instructions per
man-year were achieved by language translator groups. These
include planning done by the group, coding component test, sys-
tem test, and some support activities. They are comparable to
Han's data, so far as I can tell.
Aron's data, Hair's data, and the OS/360 data all confirm
striking differences in productivity related to the complexity and
difficulty of the task itself. My guideline in the morass of estimat-
ing complexity is that compilers are three times as bad as normal
batch application programs, and operating systems are three times
as bad as compilers.9
Corbato's Data
Both Hair's data and OS/360 data are for assembly language pro-
gramming. Little data seem to have been published on system
programming productivity using higher-level languages. Corbato
of MIT's Project MAC reports, however, a mean productivity of
1200 lines of debugged PL/I statements per man-year on the
MULTICS system (between 1 and 2 million words).10
This number is very exciting. Like the other projects, MUL-
TICS includes control programs and language translators. Like the
others, it is producing a system programming product, tested and
documented. The data seem to be comparable in terms of kind of
effort included. And the productivity number is a good average
between the control program and translator productivities of other
projects.
But Corbato's number is lines per man-year, not wordsl Each
statement in his system corresponds to about three to five words
of handwritten code! This suggests two important conclusions.
94 Calling the Shot
Productivity seems constant in tenns of elementary state-
ments, a conclusion that is reasonable in terms of the thought
a statement requires and the errors it may include."
Programming productivity may be increased as much as five
times when a suitable high-level language is used.18
•
•
